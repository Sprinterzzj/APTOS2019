{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T09:06:57.825162Z",
     "start_time": "2019-08-24T09:06:57.820706Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from seaborn import heatmap\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from fastai.vision import *\n",
    "from torch.nn import functional as F\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T09:01:06.568266Z",
     "start_time": "2019-08-24T09:01:06.564362Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0824_17-01-06\n"
     ]
    }
   ],
   "source": [
    "current_time = get_BJ_time()\n",
    "print(current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T09:01:06.629184Z",
     "start_time": "2019-08-24T09:01:06.573930Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "SEED = 2019\n",
    "seed_everything(SEED)\n",
    "\n",
    "deployment_dir = \"../output/inference\"\n",
    "\n",
    "def qk(y_pred, y):\n",
    "    k = torch.tensor(cohen_kappa_score(torch.round(y_pred), y, weights='quadratic'), device='cuda:0')\n",
    "    k[k != k] = 0\n",
    "    k[torch.isinf(k)] = 0\n",
    "    \n",
    "    return k\n",
    "\n",
    "df_2019_cv = pd.read_csv('../input/aptos-data-split/df_2019_cv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T09:01:06.666673Z",
     "start_time": "2019-08-24T09:01:06.635930Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>path</th>\n",
       "      <th>is_valid1</th>\n",
       "      <th>is_valid2</th>\n",
       "      <th>is_valid3</th>\n",
       "      <th>is_valid4</th>\n",
       "      <th>is_valid5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000c1434d8d7</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/aptos2019-blindness-detection/train_i...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001639a390f0</td>\n",
       "      <td>4</td>\n",
       "      <td>../input/aptos2019-blindness-detection/train_i...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0024cdab0c1e</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/aptos2019-blindness-detection/train_i...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002c21358ce6</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/aptos2019-blindness-detection/train_i...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005b95c28852</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/aptos2019-blindness-detection/train_i...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_code  diagnosis                                               path  \\\n",
       "0  000c1434d8d7          2  ../input/aptos2019-blindness-detection/train_i...   \n",
       "1  001639a390f0          4  ../input/aptos2019-blindness-detection/train_i...   \n",
       "2  0024cdab0c1e          1  ../input/aptos2019-blindness-detection/train_i...   \n",
       "3  002c21358ce6          0  ../input/aptos2019-blindness-detection/train_i...   \n",
       "4  005b95c28852          0  ../input/aptos2019-blindness-detection/train_i...   \n",
       "\n",
       "   is_valid1  is_valid2  is_valid3  is_valid4  is_valid5  \n",
       "0       True      False      False      False      False  \n",
       "1       True      False      False      False      False  \n",
       "2       True      False      False      False      False  \n",
       "3       True      False      False      False      False  \n",
       "4       True      False      False      False      False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2019_cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T09:01:06.675869Z",
     "start_time": "2019-08-24T09:01:06.668965Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../input/aptos2019-blindness-detection/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:52:08.556127Z",
     "start_time": "2019-08-22T17:52:08.554197Z"
    }
   },
   "source": [
    "## Train Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T10:18:09.151417Z",
     "start_time": "2019-08-22T10:17:58.058921Z"
    }
   },
   "outputs": [],
   "source": [
    "fold = 1\n",
    "val_df = df_2019_cv[df_2019_cv[\"is_valid{}\".format(fold)]]\n",
    "\n",
    "learn = load_learner(deployment_dir, \"efficientnet-b3_0819_22-37-22_stage2_f1.pkl\")\n",
    "\n",
    "learn.data.add_test(ImageList.from_df(val_df,\n",
    "                                      '../input/aptos2019-blindness-detection',\n",
    "                                      cols=\"id_code\",\n",
    "                                      folder='train_images_ben_preprocessing',\n",
    "                                      suffix='.png'))\n",
    "\n",
    "learn.model.eval()\n",
    "with torch.no_grad():\n",
    "    feats_list = []\n",
    "    for xb,yb in tqdm_notebook(learn.data.test_dl):\n",
    "        # Convolution layers\n",
    "        x = learn.model.extract_features(xb)\n",
    "        \n",
    "        # Pooling and final linear layer\n",
    "        feats = F.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n",
    "        feats = feats.cpu().numpy()\n",
    "        feats_list.append(feats)\n",
    "\n",
    "feats_arr = np.concatenate(feats_list, axis=0)\n",
    "np.save(\"../output/stacking/b3_f{}_feats.npy\".format(fold), feats_arr)\n",
    "\n",
    "print(feats_arr.shape)\n",
    "\n",
    "fold = 2\n",
    "val_df = df_2019_cv[df_2019_cv[\"is_valid{}\".format(fold)]]\n",
    "\n",
    "learn = load_learner(deployment_dir, \"efficientnet-b3_0819_22-37-22_stage2_f2.pkl\")\n",
    "\n",
    "learn.data.add_test(ImageList.from_df(val_df,\n",
    "                                      '../input/aptos2019-blindness-detection',\n",
    "                                      cols=\"id_code\",\n",
    "                                      folder='train_images_ben_preprocessing',\n",
    "                                      suffix='.png'))\n",
    "\n",
    "learn.model.eval()\n",
    "with torch.no_grad():\n",
    "    feats_list = []\n",
    "    for xb,yb in tqdm_notebook(learn.data.test_dl):\n",
    "        # Convolution layers\n",
    "        x = learn.model.extract_features(xb)\n",
    "        \n",
    "        # Pooling and final linear layer\n",
    "        feats = F.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n",
    "        feats = feats.cpu().numpy()\n",
    "        feats_list.append(feats)\n",
    "\n",
    "feats_arr = np.concatenate(feats_list, axis=0)\n",
    "np.save(\"../output/stacking/b3_f{}_feats.npy\".format(fold), feats_arr)\n",
    "\n",
    "print(feats_arr.shape)\n",
    "\n",
    "fold = 3\n",
    "val_df = df_2019_cv[df_2019_cv[\"is_valid{}\".format(fold)]]\n",
    "\n",
    "learn = load_learner(deployment_dir, \"efficientnet-b3_0819_22-37-22_stage2_f3.pkl\")\n",
    "\n",
    "learn.data.add_test(ImageList.from_df(val_df,\n",
    "                                      '../input/aptos2019-blindness-detection',\n",
    "                                      cols=\"id_code\",\n",
    "                                      folder='train_images_ben_preprocessing',\n",
    "                                      suffix='.png'))\n",
    "\n",
    "learn.model.eval()\n",
    "with torch.no_grad():\n",
    "    feats_list = []\n",
    "    for xb,yb in tqdm_notebook(learn.data.test_dl):\n",
    "        # Convolution layers\n",
    "        x = learn.model.extract_features(xb)\n",
    "        \n",
    "        # Pooling and final linear layer\n",
    "        feats = F.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n",
    "        feats = feats.cpu().numpy()\n",
    "        feats_list.append(feats)\n",
    "\n",
    "feats_arr = np.concatenate(feats_list, axis=0)\n",
    "np.save(\"../output/stacking/b3_f{}_feats.npy\".format(fold), feats_arr)\n",
    "\n",
    "print(feats_arr.shape)\n",
    "\n",
    "fold = 4\n",
    "val_df = df_2019_cv[df_2019_cv[\"is_valid{}\".format(fold)]]\n",
    "\n",
    "learn = load_learner(deployment_dir, \"efficientnet-b3_0819_22-37-22_stage2_f4.pkl\")\n",
    "\n",
    "learn.data.add_test(ImageList.from_df(val_df,\n",
    "                                      '../input/aptos2019-blindness-detection',\n",
    "                                      cols=\"id_code\",\n",
    "                                      folder='train_images_ben_preprocessing',\n",
    "                                      suffix='.png'))\n",
    "\n",
    "learn.model.eval()\n",
    "with torch.no_grad():\n",
    "    feats_list = []\n",
    "    for xb,yb in tqdm_notebook(learn.data.test_dl):\n",
    "        # Convolution layers\n",
    "        x = learn.model.extract_features(xb)\n",
    "        \n",
    "        # Pooling and final linear layer\n",
    "        feats = F.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n",
    "        feats = feats.cpu().numpy()\n",
    "        feats_list.append(feats)\n",
    "\n",
    "feats_arr = np.concatenate(feats_list, axis=0)\n",
    "np.save(\"../output/stacking/b3_f{}_feats.npy\".format(fold), feats_arr)\n",
    "\n",
    "print(feats_arr.shape)\n",
    "\n",
    "fold = 5\n",
    "val_df = df_2019_cv[df_2019_cv[\"is_valid{}\".format(fold)]]\n",
    "\n",
    "learn = load_learner(deployment_dir, \"efficientnet-b3_0820_05-48-25_stage2_f5.pkl\")\n",
    "\n",
    "learn.data.add_test(ImageList.from_df(val_df,\n",
    "                                      '../input/aptos2019-blindness-detection',\n",
    "                                      cols=\"id_code\",\n",
    "                                      folder='train_images_ben_preprocessing',\n",
    "                                      suffix='.png'))\n",
    "\n",
    "learn.model.eval()\n",
    "with torch.no_grad():\n",
    "    feats_list = []\n",
    "    for xb,yb in tqdm_notebook(learn.data.test_dl):\n",
    "        # Convolution layers\n",
    "        x = learn.model.extract_features(xb)\n",
    "        \n",
    "        # Pooling and final linear layer\n",
    "        feats = F.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n",
    "        feats = feats.cpu().numpy()\n",
    "        feats_list.append(feats)\n",
    "\n",
    "feats_arr = np.concatenate(feats_list, axis=0)\n",
    "np.save(\"../output/stacking/b3_f{}_feats.npy\".format(fold), feats_arr)\n",
    "\n",
    "print(feats_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T10:34:16.286244Z",
     "start_time": "2019-08-22T10:33:57.817062Z"
    }
   },
   "outputs": [],
   "source": [
    "fold = 1\n",
    "val_df = df_2019_cv[df_2019_cv[\"is_valid{}\".format(fold)]]\n",
    "\n",
    "learn = load_learner(deployment_dir, \"efficientnet-b4_0820_01-09-57_stage2_f1.pkl\")\n",
    "\n",
    "learn.data.add_test(ImageList.from_df(val_df,\n",
    "                                      '../input/aptos2019-blindness-detection',\n",
    "                                      cols=\"id_code\",\n",
    "                                      folder='train_images_ben_preprocessing_sigmaX10',\n",
    "                                      suffix='.png'))\n",
    "\n",
    "learn.model.eval()\n",
    "with torch.no_grad():\n",
    "    feats_list = []\n",
    "    for xb,yb in tqdm_notebook(learn.data.test_dl):\n",
    "        # Convolution layers\n",
    "        x = learn.model.extract_features(xb)\n",
    "        \n",
    "        # Pooling and final linear layer\n",
    "        feats = F.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n",
    "        feats = feats.cpu().numpy()\n",
    "        feats_list.append(feats)\n",
    "\n",
    "feats_arr = np.concatenate(feats_list, axis=0)\n",
    "np.save(\"../output/stacking/b4_f{}_feats.npy\".format(fold), feats_arr)\n",
    "\n",
    "print(feats_arr.shape)\n",
    "\n",
    "fold = 2\n",
    "val_df = df_2019_cv[df_2019_cv[\"is_valid{}\".format(fold)]]\n",
    "\n",
    "learn = load_learner(deployment_dir, \"efficientnet-b4_0820_01-09-57_stage2_f2.pkl\")\n",
    "\n",
    "learn.data.add_test(ImageList.from_df(val_df,\n",
    "                                      '../input/aptos2019-blindness-detection',\n",
    "                                      cols=\"id_code\",\n",
    "                                      folder='train_images_ben_preprocessing_sigmaX10',\n",
    "                                      suffix='.png'))\n",
    "\n",
    "learn.model.eval()\n",
    "with torch.no_grad():\n",
    "    feats_list = []\n",
    "    for xb,yb in tqdm_notebook(learn.data.test_dl):\n",
    "        # Convolution layers\n",
    "        x = learn.model.extract_features(xb)\n",
    "        \n",
    "        # Pooling and final linear layer\n",
    "        feats = F.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n",
    "        feats = feats.cpu().numpy()\n",
    "        feats_list.append(feats)\n",
    "\n",
    "feats_arr = np.concatenate(feats_list, axis=0)\n",
    "np.save(\"../output/stacking/b4_f{}_feats.npy\".format(fold), feats_arr)\n",
    "\n",
    "print(feats_arr.shape)\n",
    "\n",
    "fold = 3\n",
    "val_df = df_2019_cv[df_2019_cv[\"is_valid{}\".format(fold)]]\n",
    "\n",
    "learn = load_learner(deployment_dir, \"efficientnet-b4_0820_01-09-57_stage2_f3.pkl\")\n",
    "\n",
    "learn.data.add_test(ImageList.from_df(val_df,\n",
    "                                      '../input/aptos2019-blindness-detection',\n",
    "                                      cols=\"id_code\",\n",
    "                                      folder='train_images_ben_preprocessing_sigmaX10',\n",
    "                                      suffix='.png'))\n",
    "\n",
    "learn.model.eval()\n",
    "with torch.no_grad():\n",
    "    feats_list = []\n",
    "    for xb,yb in tqdm_notebook(learn.data.test_dl):\n",
    "        # Convolution layers\n",
    "        x = learn.model.extract_features(xb)\n",
    "        \n",
    "        # Pooling and final linear layer\n",
    "        feats = F.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n",
    "        feats = feats.cpu().numpy()\n",
    "        feats_list.append(feats)\n",
    "\n",
    "feats_arr = np.concatenate(feats_list, axis=0)\n",
    "np.save(\"../output/stacking/b4_f{}_feats.npy\".format(fold), feats_arr)\n",
    "\n",
    "print(feats_arr.shape)\n",
    "\n",
    "fold = 4\n",
    "val_df = df_2019_cv[df_2019_cv[\"is_valid{}\".format(fold)]]\n",
    "\n",
    "learn = load_learner(deployment_dir, \"efficientnet-b4_0820_01-09-57_stage2_f4.pkl\")\n",
    "\n",
    "learn.data.add_test(ImageList.from_df(val_df,\n",
    "                                      '../input/aptos2019-blindness-detection',\n",
    "                                      cols=\"id_code\",\n",
    "                                      folder='train_images_ben_preprocessing_sigmaX10',\n",
    "                                      suffix='.png'))\n",
    "\n",
    "learn.model.eval()\n",
    "with torch.no_grad():\n",
    "    feats_list = []\n",
    "    for xb,yb in tqdm_notebook(learn.data.test_dl):\n",
    "        # Convolution layers\n",
    "        x = learn.model.extract_features(xb)\n",
    "        \n",
    "        # Pooling and final linear layer\n",
    "        feats = F.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n",
    "        feats = feats.cpu().numpy()\n",
    "        feats_list.append(feats)\n",
    "\n",
    "feats_arr = np.concatenate(feats_list, axis=0)\n",
    "np.save(\"../output/stacking/b4_f{}_feats.npy\".format(fold), feats_arr)\n",
    "\n",
    "print(feats_arr.shape)\n",
    "\n",
    "fold = 5\n",
    "val_df = df_2019_cv[df_2019_cv[\"is_valid{}\".format(fold)]]\n",
    "\n",
    "learn = load_learner(deployment_dir, \"efficientnet-b4_0821_00-02-25_stage2_f5.pkl\")\n",
    "\n",
    "learn.data.add_test(ImageList.from_df(val_df,\n",
    "                                      '../input/aptos2019-blindness-detection',\n",
    "                                      cols=\"id_code\",\n",
    "                                      folder='train_images_ben_preprocessing_sigmaX10',\n",
    "                                      suffix='.png'))\n",
    "\n",
    "learn.model.eval()\n",
    "with torch.no_grad():\n",
    "    feats_list = []\n",
    "    for xb,yb in tqdm_notebook(learn.data.test_dl):\n",
    "        # Convolution layers\n",
    "        x = learn.model.extract_features(xb)\n",
    "        \n",
    "        # Pooling and final linear layer\n",
    "        feats = F.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n",
    "        feats = feats.cpu().numpy()\n",
    "        feats_list.append(feats)\n",
    "\n",
    "feats_arr = np.concatenate(feats_list, axis=0)\n",
    "np.save(\"../output/stacking/b4_f{}_feats.npy\".format(fold), feats_arr)\n",
    "\n",
    "print(feats_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T11:43:44.589911Z",
     "start_time": "2019-08-22T11:43:23.141170Z"
    }
   },
   "outputs": [],
   "source": [
    "fold = 1\n",
    "val_df = df_2019_cv[df_2019_cv[\"is_valid{}\".format(fold)]]\n",
    "\n",
    "learn = load_learner(deployment_dir, \"efficientnet-b5_0820_01-32-30_stage2_f1.pkl\")\n",
    "\n",
    "learn.data.add_test(ImageList.from_df(val_df,\n",
    "                                      '../input/aptos2019-blindness-detection',\n",
    "                                      cols=\"id_code\",\n",
    "                                      folder='train_images_ben_preprocessing_sigmaX10',\n",
    "                                      suffix='.png'))\n",
    "\n",
    "learn.model.eval()\n",
    "with torch.no_grad():\n",
    "    feats_list = []\n",
    "    for xb,yb in tqdm_notebook(learn.data.test_dl):\n",
    "        # Convolution layers\n",
    "        x = learn.model.extract_features(xb)\n",
    "        \n",
    "        # Pooling and final linear layer\n",
    "        feats = F.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n",
    "        feats = feats.cpu().numpy()\n",
    "        feats_list.append(feats)\n",
    "\n",
    "feats_arr = np.concatenate(feats_list, axis=0)\n",
    "np.save(\"../output/stacking/b5_f{}_feats.npy\".format(fold), feats_arr)\n",
    "\n",
    "print(feats_arr.shape)\n",
    "\n",
    "fold = 2\n",
    "val_df = df_2019_cv[df_2019_cv[\"is_valid{}\".format(fold)]]\n",
    "\n",
    "learn = load_learner(deployment_dir, \"efficientnet-b5_0820_22-13-07_stage2_f2.pkl\")\n",
    "\n",
    "learn.data.add_test(ImageList.from_df(val_df,\n",
    "                                      '../input/aptos2019-blindness-detection',\n",
    "                                      cols=\"id_code\",\n",
    "                                      folder='train_images_ben_preprocessing_sigmaX10',\n",
    "                                      suffix='.png'))\n",
    "\n",
    "learn.model.eval()\n",
    "with torch.no_grad():\n",
    "    feats_list = []\n",
    "    for xb,yb in tqdm_notebook(learn.data.test_dl):\n",
    "        # Convolution layers\n",
    "        x = learn.model.extract_features(xb)\n",
    "        \n",
    "        # Pooling and final linear layer\n",
    "        feats = F.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n",
    "        feats = feats.cpu().numpy()\n",
    "        feats_list.append(feats)\n",
    "\n",
    "feats_arr = np.concatenate(feats_list, axis=0)\n",
    "np.save(\"../output/stacking/b5_f{}_feats.npy\".format(fold), feats_arr)\n",
    "\n",
    "print(feats_arr.shape)\n",
    "\n",
    "fold = 3\n",
    "val_df = df_2019_cv[df_2019_cv[\"is_valid{}\".format(fold)]]\n",
    "\n",
    "learn = load_learner(deployment_dir, \"efficientnet-b5_0820_22-13-07_stage2_f3.pkl\")\n",
    "\n",
    "learn.data.add_test(ImageList.from_df(val_df,\n",
    "                                      '../input/aptos2019-blindness-detection',\n",
    "                                      cols=\"id_code\",\n",
    "                                      folder='train_images_ben_preprocessing_sigmaX10',\n",
    "                                      suffix='.png'))\n",
    "\n",
    "learn.model.eval()\n",
    "with torch.no_grad():\n",
    "    feats_list = []\n",
    "    for xb,yb in tqdm_notebook(learn.data.test_dl):\n",
    "        # Convolution layers\n",
    "        x = learn.model.extract_features(xb)\n",
    "        \n",
    "        # Pooling and final linear layer\n",
    "        feats = F.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n",
    "        feats = feats.cpu().numpy()\n",
    "        feats_list.append(feats)\n",
    "\n",
    "feats_arr = np.concatenate(feats_list, axis=0)\n",
    "np.save(\"../output/stacking/b5_f{}_feats.npy\".format(fold), feats_arr)\n",
    "\n",
    "print(feats_arr.shape)\n",
    "\n",
    "fold = 4\n",
    "val_df = df_2019_cv[df_2019_cv[\"is_valid{}\".format(fold)]]\n",
    "\n",
    "learn = load_learner(deployment_dir, \"efficientnet-b5_0821_01-30-37_stage2_f4.pkl\")\n",
    "\n",
    "learn.data.add_test(ImageList.from_df(val_df,\n",
    "                                      '../input/aptos2019-blindness-detection',\n",
    "                                      cols=\"id_code\",\n",
    "                                      folder='train_images_ben_preprocessing_sigmaX10',\n",
    "                                      suffix='.png'))\n",
    "\n",
    "learn.model.eval()\n",
    "with torch.no_grad():\n",
    "    feats_list = []\n",
    "    for xb,yb in tqdm_notebook(learn.data.test_dl):\n",
    "        # Convolution layers\n",
    "        x = learn.model.extract_features(xb)\n",
    "        \n",
    "        # Pooling and final linear layer\n",
    "        feats = F.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n",
    "        feats = feats.cpu().numpy()\n",
    "        feats_list.append(feats)\n",
    "\n",
    "feats_arr = np.concatenate(feats_list, axis=0)\n",
    "np.save(\"../output/stacking/b5_f{}_feats.npy\".format(fold), feats_arr)\n",
    "\n",
    "print(feats_arr.shape)\n",
    "\n",
    "fold = 5\n",
    "val_df = df_2019_cv[df_2019_cv[\"is_valid{}\".format(fold)]]\n",
    "\n",
    "learn = load_learner(deployment_dir, \"efficientnet-b5_0821_00-26-51_stage2_f5.pkl\")\n",
    "\n",
    "learn.data.add_test(ImageList.from_df(val_df,\n",
    "                                      '../input/aptos2019-blindness-detection',\n",
    "                                      cols=\"id_code\",\n",
    "                                      folder='train_images_ben_preprocessing_sigmaX10',\n",
    "                                      suffix='.png'))\n",
    "\n",
    "learn.model.eval()\n",
    "with torch.no_grad():\n",
    "    feats_list = []\n",
    "    for xb,yb in tqdm_notebook(learn.data.test_dl):\n",
    "        # Convolution layers\n",
    "        x = learn.model.extract_features(xb)\n",
    "        \n",
    "        # Pooling and final linear layer\n",
    "        feats = F.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n",
    "        feats = feats.cpu().numpy()\n",
    "        feats_list.append(feats)\n",
    "\n",
    "feats_arr = np.concatenate(feats_list, axis=0)\n",
    "np.save(\"../output/stacking/b5_f{}_feats.npy\".format(fold), feats_arr)\n",
    "\n",
    "print(feats_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T11:08:00.430735Z",
     "start_time": "2019-08-23T11:08:00.427585Z"
    }
   },
   "source": [
    "### Average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T20:31:22.015853Z",
     "start_time": "2019-08-22T20:31:22.013172Z"
    }
   },
   "source": [
    "#### b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T16:28:01.173295Z",
     "start_time": "2019-08-24T16:27:32.329299Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f38da2312143ec9b338de1f5cabe40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6787be24b48471fbba56347fa59f7f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1691eaea744048bc089bf2b6688edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153af62e196b4e5896261d357a40a505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd23cf4e8b0c4d1281e1397aeacb54ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2345ab0b35d4ecd90c154304c877e45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b3_models = [\"efficientnet-b3_0819_22-37-22_stage2_f1\", \"efficientnet-b3_0819_22-37-22_stage2_f2\", \n",
    "             \"efficientnet-b3_0819_22-37-22_stage2_f3\", \"efficientnet-b3_0819_22-37-22_stage2_f4\",\n",
    "            \"efficientnet-b3_0820_05-48-25_stage2_f5\"]\n",
    "\n",
    "b3_test_feats_list = []\n",
    "for m in tqdm_notebook(b3_models):\n",
    "    learn = load_learner(deployment_dir, \"{}.pkl\".format(m))\n",
    "\n",
    "    learn.data.add_test(ImageList.from_df(test_df,\n",
    "                                      '../input/aptos2019-blindness-detection',\n",
    "                                      folder='test_images_ben_preprocessing',\n",
    "                                      suffix='.png'))\n",
    "\n",
    "    learn.model.eval()\n",
    "    with torch.no_grad():\n",
    "        feats_list = []\n",
    "        for xb,yb in tqdm_notebook(learn.data.test_dl):\n",
    "            # Convolution layers\n",
    "            x = learn.model.extract_features(xb)\n",
    "\n",
    "            # Pooling and final linear layer\n",
    "            feats = F.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n",
    "            feats = feats.cpu().numpy()\n",
    "            feats_list.append(feats)\n",
    "            \n",
    "    feats_arr = np.concatenate(feats_list, axis=0)\n",
    "    b3_test_feats_list.append(feats_arr)\n",
    "    \n",
    "b3_test_feats = np.average(b3_test_feats, axis=0)\n",
    "np.save(\"../output/stacking/b3_test_feats.npy\", b3_test_feats)\n",
    "# print(b3_test_feats.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T16:28:35.319197Z",
     "start_time": "2019-08-24T16:28:01.175435Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6c02437f067468f888c8ce1bf4f5689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c3de7afe95047519686e62c60e58f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d8404461dd5425fbdd09232fc6639b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c085a7813e417293c9b427045a6087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d78936a17dc4fc1bd6b1cf6916cac3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d88040443c024154a5df98f221177002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b4_models = [\"efficientnet-b4_0820_01-09-57_stage2_f1\", \"efficientnet-b4_0820_01-09-57_stage2_f2\", \n",
    "             \"efficientnet-b4_0820_01-09-57_stage2_f3\", \"efficientnet-b4_0820_01-09-57_stage2_f4\",\n",
    "            \"efficientnet-b4_0821_00-02-25_stage2_f5\"]\n",
    "\n",
    "b4_test_feats_list = []\n",
    "for m in tqdm_notebook(b4_models):\n",
    "    learn = load_learner(deployment_dir, \"{}.pkl\".format(m))\n",
    "\n",
    "    learn.data.add_test(ImageList.from_df(test_df,\n",
    "                                      '../input/aptos2019-blindness-detection',\n",
    "                                      folder='test_images_ben_preprocessing_sigmaX10',\n",
    "                                      suffix='.png'))\n",
    "\n",
    "    learn.model.eval()\n",
    "    with torch.no_grad():\n",
    "        feats_list = []\n",
    "        for xb,yb in tqdm_notebook(learn.data.test_dl):\n",
    "            # Convolution layers\n",
    "            x = learn.model.extract_features(xb)\n",
    "\n",
    "            # Pooling and final linear layer\n",
    "            feats = F.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n",
    "            feats = feats.cpu().numpy()\n",
    "            feats_list.append(feats)\n",
    "            \n",
    "    feats_arr = np.concatenate(feats_list, axis=0)\n",
    "    b4_test_feats_list.append(feats_arr)\n",
    "    \n",
    "b4_test_feats = np.average(b4_test_feats, axis=0)\n",
    "np.save(\"../output/stacking/b4_test_feats.npy\", b4_test_feats)\n",
    "\n",
    "# print(b4_test_feats.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T16:36:51.921925Z",
     "start_time": "2019-08-24T16:36:09.927390Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66b72acc3ee740dc97883503952d01a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f7d71203d2403586a2b5a11776440a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0a17e232aa543a49e457e77ea35000a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ebadd4472b479e8d70321e402ef52c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "372d1c14581440b7a5b11475005c4f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "361f519447ed4cb8bfcc001776ed361a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b5_models = [\"efficientnet-b5_0820_01-32-30_stage2_f1\", \"efficientnet-b5_0820_22-13-07_stage2_f2\", \n",
    "             \"efficientnet-b5_0820_22-13-07_stage2_f3\", \"efficientnet-b5_0821_01-30-37_stage2_f4\",\n",
    "            \"efficientnet-b5_0821_00-26-51_stage2_f5\"]\n",
    "\n",
    "b5_test_feats_list = []\n",
    "for m in tqdm_notebook(b5_models):\n",
    "    learn = load_learner(deployment_dir, \"{}.pkl\".format(m))\n",
    "\n",
    "    learn.data.add_test(ImageList.from_df(test_df,\n",
    "                                      '../input/aptos2019-blindness-detection',\n",
    "                                      folder='test_images_ben_preprocessing_sigmaX10',\n",
    "                                      suffix='.png'))\n",
    "\n",
    "    learn.model.eval()\n",
    "    with torch.no_grad():\n",
    "        feats_list = []\n",
    "        for xb,yb in tqdm_notebook(learn.data.test_dl):\n",
    "            # Convolution layers\n",
    "            x = learn.model.extract_features(xb)\n",
    "\n",
    "            # Pooling and final linear layer\n",
    "            feats = F.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n",
    "            feats = feats.cpu().numpy()\n",
    "            feats_list.append(feats)\n",
    "            \n",
    "    feats_arr = np.concatenate(feats_list, axis=0)\n",
    "    b5_test_feats_list.append(feats_arr)\n",
    "    \n",
    "b5_test_feats = np.average(b5_test_feats, axis=0)\n",
    "np.save(\"../output/stacking/b5_test_feats.npy\", b5_test_feats)\n",
    "\n",
    "# print(b5_test_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T16:35:55.750675Z",
     "start_time": "2019-08-24T16:35:55.746319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048,)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b5_test_feats_list.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T11:09:06.212380Z",
     "start_time": "2019-08-23T11:09:06.208703Z"
    }
   },
   "source": [
    "#### b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T17:15:16.442081Z",
     "start_time": "2019-08-24T17:15:10.759769Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "624c3675832c482ebd45ed2145daf0da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1928, 1536)\n"
     ]
    }
   ],
   "source": [
    "b3_test_feats = []\n",
    "learn = load_learner(deployment_dir, \"efficientnet-b3_0823_05-02-32_stage2_whole.pkl\")\n",
    "\n",
    "learn.data.add_test(ImageList.from_df(test_df,\n",
    "                                  '../input/aptos2019-blindness-detection',\n",
    "                                  folder='test_images_ben_preprocessing',\n",
    "                                  suffix='.png'))\n",
    "\n",
    "learn.model.eval()\n",
    "with torch.no_grad():\n",
    "    feats_list = []\n",
    "    for xb,yb in tqdm_notebook(learn.data.test_dl):\n",
    "        # Convolution layers\n",
    "        x = learn.model.extract_features(xb)\n",
    "\n",
    "        # Pooling and final linear layer\n",
    "        feats = F.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n",
    "        feats = feats.cpu().numpy()\n",
    "        feats_list.append(feats)\n",
    "            \n",
    "feats_arr = np.concatenate(feats_list, axis=0)\n",
    "#     b3_test_feats.append(feats_arr)\n",
    "    \n",
    "# b3_test_feats = np.average(b3_test_feats, axis=0)\n",
    "np.save(\"../output/stacking/b3_retrain_test_feats.npy\", b3_test_feats)\n",
    "b3_test_feats = feats_arr\n",
    "print(b3_test_feats.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T11:09:06.212380Z",
     "start_time": "2019-08-23T11:09:06.208703Z"
    }
   },
   "source": [
    "#### b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T17:15:23.323214Z",
     "start_time": "2019-08-24T17:15:16.445340Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5154adb22d1460ca626f753c3595e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1928, 1792)\n"
     ]
    }
   ],
   "source": [
    "b4_test_feats = []\n",
    "learn = load_learner(deployment_dir, \"efficientnet-b4_0823_18-14-19_stage2_whole.pkl\")\n",
    "\n",
    "learn.data.add_test(ImageList.from_df(test_df,\n",
    "                                  '../input/aptos2019-blindness-detection',\n",
    "                                  folder='test_images_ben_preprocessing_sigmaX10',\n",
    "                                  suffix='.png'))\n",
    "\n",
    "learn.model.eval()\n",
    "with torch.no_grad():\n",
    "    feats_list = []\n",
    "    for xb,yb in tqdm_notebook(learn.data.test_dl):\n",
    "        # Convolution layers\n",
    "        x = learn.model.extract_features(xb)\n",
    "\n",
    "        # Pooling and final linear layer\n",
    "        feats = F.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n",
    "        feats = feats.cpu().numpy()\n",
    "        feats_list.append(feats)\n",
    "\n",
    "feats_arr = np.concatenate(feats_list, axis=0)\n",
    "b4_test_feats = feats_arr\n",
    "    \n",
    "np.save(\"../output/stacking/b4_retrain_test_feats.npy\", b4_test_feats)\n",
    "\n",
    "print(b4_test_feats.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T11:09:06.212380Z",
     "start_time": "2019-08-23T11:09:06.208703Z"
    }
   },
   "source": [
    "#### b5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T17:15:31.586361Z",
     "start_time": "2019-08-24T17:15:23.325622Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c156861252d4d8697f3e07acafc25ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1928, 2048)\n"
     ]
    }
   ],
   "source": [
    "b5_test_feats = []\n",
    "learn = load_learner(deployment_dir, \"efficientnet-b5_0823_18-21-16_stage2_whole.pkl\")\n",
    "\n",
    "learn.data.add_test(ImageList.from_df(test_df,\n",
    "                                  '../input/aptos2019-blindness-detection',\n",
    "                                  folder='test_images_ben_preprocessing_sigmaX10',\n",
    "                                  suffix='.png'))\n",
    "\n",
    "learn.model.eval()\n",
    "with torch.no_grad():\n",
    "    feats_list = []\n",
    "    for xb,yb in tqdm_notebook(learn.data.test_dl):\n",
    "        # Convolution layers\n",
    "        x = learn.model.extract_features(xb)\n",
    "\n",
    "        # Pooling and final linear layer\n",
    "        feats = F.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n",
    "        feats = feats.cpu().numpy()\n",
    "        feats_list.append(feats)\n",
    "\n",
    "feats_arr = np.concatenate(feats_list, axis=0)\n",
    "b5_test_feats = feats_arr\n",
    "    \n",
    "np.save(\"../output/stacking/b5_retrain_test_feats.npy\", b5_test_feats)\n",
    "\n",
    "print(b5_test_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T17:15:31.618759Z",
     "start_time": "2019-08-24T17:15:31.588451Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1928, 5376)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.concatenate([b3_test_feats, b4_test_feats, b5_test_feats], axis=1)\n",
    "# X_test = np.concatenate([b4_test_feats, b5_test_feats], axis=1)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T14:03:21.632429Z",
     "start_time": "2019-08-22T14:03:21.627914Z"
    }
   },
   "source": [
    "# Train Stage 2 model on OOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T09:01:31.500114Z",
     "start_time": "2019-08-24T09:01:31.470603Z"
    }
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T09:01:33.037940Z",
     "start_time": "2019-08-24T09:01:33.031760Z"
    }
   },
   "outputs": [],
   "source": [
    "def qk_np(y, y_pred):\n",
    "    k = cohen_kappa_score(np.round(y_pred), y, weights='quadratic')\n",
    "    \n",
    "    return k\n",
    "\n",
    "score = make_scorer(qk_np, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T09:12:34.670914Z",
     "start_time": "2019-08-24T09:12:34.512099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3662, 5376)\n"
     ]
    }
   ],
   "source": [
    "stacking_dir = \"../output/stacking\"\n",
    "X_train = []\n",
    "y_train = []\n",
    "n_fold = 5\n",
    "\n",
    "for i in range(1, n_fold+1):\n",
    "    data_t = []\n",
    "    for j in ['b3_f{}_feats.npy', 'b4_f{}_feats.npy', 'b5_f{}_feats.npy']:\n",
    "#     for j in ['b4_f{}_feats.npy', 'b5_f{}_feats.npy']:\n",
    "        data_t.append(np.load(os.path.join(stacking_dir, j.format(i))))\n",
    "    data_t = np.concatenate(data_t, axis=1)\n",
    "    X_train.append(data_t)\n",
    "    \n",
    "    label_t = df_2019_cv[df_2019_cv[\"is_valid{}\".format(i)]][\"diagnosis\"].tolist()\n",
    "    y_train += label_t\n",
    "    \n",
    "X_train = np.concatenate(X_train, axis=0)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T10:42:35.850060Z",
     "start_time": "2019-08-24T10:42:35.668043Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T17:28:19.054229Z",
     "start_time": "2019-08-23T17:28:19.036958Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_normalized = F.softmax(torch.tensor(X_train)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T09:13:24.329118Z",
     "start_time": "2019-08-24T09:12:38.236224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   5 out of   5 | elapsed:   29.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by grid search are: {'learning_rate': 0.1, 'max_depth': 20}\n"
     ]
    }
   ],
   "source": [
    "estimator = lgb.LGBMRegressor(n_jobs=8, random_state=SEED)\n",
    "\n",
    "param_grid = {\n",
    "#     'max_depth': [15, 20, 25, 30, 35],   \n",
    "    'max_depth': [20],\n",
    "#     'learning_rate': [0.01, 0.02, 0.05, 0.1, 0.15],    \n",
    "    'learning_rate': [0.1],\n",
    "#     'feature_fraction': [0.6, 0.7, 0.8, 0.9, 0.95],\n",
    "#     'bagging_fraction': [0.6, 0.7, 0.8, 0.9, 0.95],\n",
    "#     'bagging_freq': [2, 4, 5, 6, 8],\n",
    "#     'lambda_l1': [0, 0.1, 0.4, 0.5, 0.6],\n",
    "#     'lambda_l2': [0, 10, 15, 35, 40],\n",
    "#     'cat_smooth': [1, 10, 15, 20, 35]\n",
    "}\n",
    "\n",
    "gbm = GridSearchCV(estimator, param_grid, cv=5, n_jobs=16, scoring=score, verbose=1)\n",
    "# gbm.fit(X_train_normalized, y_train)\n",
    "gbm.fit(X_train, y_train)\n",
    "\n",
    "print('Best parameters found by grid search are:', gbm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T09:13:24.339321Z",
     "start_time": "2019-08-24T09:13:24.331929Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([26.503971]),\n",
       " 'std_fit_time': array([0.53958]),\n",
       " 'mean_score_time': array([0.014936]),\n",
       " 'std_score_time': array([0.004083]),\n",
       " 'param_learning_rate': masked_array(data=[0.1],\n",
       "              mask=[False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[20],\n",
       "              mask=[False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'learning_rate': 0.1, 'max_depth': 20}],\n",
       " 'split0_test_score': array([0.927655]),\n",
       " 'split1_test_score': array([0.924255]),\n",
       " 'split2_test_score': array([0.922097]),\n",
       " 'split3_test_score': array([0.914574]),\n",
       " 'split4_test_score': array([0.912803]),\n",
       " 'mean_test_score': array([0.92028]),\n",
       " 'std_test_score': array([0.005692]),\n",
       " 'rank_test_score': array([1], dtype=int32)}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm.cv_results_   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T09:13:24.350918Z",
     "start_time": "2019-08-24T09:13:24.341161Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../output/inference/lightgbm-0824_17-01-06.pkl\n"
     ]
    }
   ],
   "source": [
    "model_save_name = os.path.join(deployment_dir, \"lightgbm-{}.pkl\".format(current_time))\n",
    "\n",
    "with open(model_save_name, \"wb\") as f:\n",
    "    pk.dump(gbm.best_estimator_, f)\n",
    "\n",
    "print(model_save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:51:11.379092Z",
     "start_time": "2019-08-22T17:51:11.368181Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(model_save_name, \"rb\") as f:\n",
    "    gbm = pk.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T09:33:44.020345Z",
     "start_time": "2019-08-24T09:33:44.017848Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T16:25:42.599249Z",
     "start_time": "2019-08-24T16:18:38.129249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  10 out of  20 | elapsed:  4.6min remaining:  4.6min\n",
      "[Parallel(n_jobs=16)]: Done  20 out of  20 | elapsed:  6.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by grid search are: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "estimator = LogisticRegression(n_jobs=8, random_state=SEED, multi_class=\"auto\")\n",
    "\n",
    "param_grid = {\n",
    "#     'penalty': ['l1', 'l2'],    \n",
    "    'penalty': ['l2'],\n",
    "    'C': [0.1],    \n",
    "    'solver': ['newton-cg', 'sag', 'saga', 'lbfgs']\n",
    "#     'C': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "}\n",
    "\n",
    "lr = GridSearchCV(estimator, param_grid, cv=5, n_jobs=16, scoring=score, verbose=1)\n",
    "lr.fit(X_train, y_train)\n",
    "# lr.fit(X_train_normalized, y_train)\n",
    "\n",
    "\n",
    "print('Best parameters found by grid search are:', lr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T16:25:42.619795Z",
     "start_time": "2019-08-24T16:25:42.601564Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([292.200948, 277.65664 , 388.242563,  24.270948]),\n",
       " 'std_fit_time': array([22.441194,  6.371762,  4.092036,  4.390133]),\n",
       " 'mean_score_time': array([0.040252, 0.08123 , 0.031822, 0.053818]),\n",
       " 'std_score_time': array([0.015878, 0.021969, 0.010026, 0.035091]),\n",
       " 'param_C': masked_array(data=[0.1, 0.1, 0.1, 0.1],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_penalty': masked_array(data=['l2', 'l2', 'l2', 'l2'],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_solver': masked_array(data=['newton-cg', 'sag', 'saga', 'lbfgs'],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'},\n",
       "  {'C': 0.1, 'penalty': 'l2', 'solver': 'sag'},\n",
       "  {'C': 0.1, 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}],\n",
       " 'split0_test_score': array([0.914614, 0.913252, 0.913252, 0.913683]),\n",
       " 'split1_test_score': array([0.925745, 0.924687, 0.924687, 0.925087]),\n",
       " 'split2_test_score': array([0.927716, 0.926291, 0.926291, 0.926291]),\n",
       " 'split3_test_score': array([0.916289, 0.914252, 0.914252, 0.914695]),\n",
       " 'split4_test_score': array([0.910075, 0.917312, 0.917312, 0.917312]),\n",
       " 'mean_test_score': array([0.918893, 0.919161, 0.919161, 0.919416]),\n",
       " 'std_test_score': array([0.006747, 0.005364, 0.005364, 0.005274]),\n",
       " 'rank_test_score': array([4, 2, 2, 1], dtype=int32)}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.cv_results_   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T16:25:42.769254Z",
     "start_time": "2019-08-24T16:25:42.621954Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9329582729509046"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qk_np(y_train, lr.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T10:03:31.957602Z",
     "start_time": "2019-08-24T10:03:31.950493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr-0824_17-01-06\n"
     ]
    }
   ],
   "source": [
    "model_save_name = \"lr-{}\".format(current_time)\n",
    "\n",
    "with open(os.path.join(deployment_dir, model_save_name+\".pkl\"), \"wb\") as f:\n",
    "    pk.dump(lr.best_estimator_, f)\n",
    "\n",
    "print(model_save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T13:29:00.393055Z",
     "start_time": "2019-08-23T13:29:00.364397Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test_normalized = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-23T17:30:19.465680Z",
     "start_time": "2019-08-23T17:30:19.453320Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test_normalized = F.softmax(torch.tensor(X_test)).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain feature test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T17:15:38.223626Z",
     "start_time": "2019-08-24T17:15:37.929182Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr-0824_17-01-06-retrain_feature_test.csv\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "\n",
    "test_df.diagnosis = y_pred.astype(int)\n",
    "\n",
    "test_df.hist()\n",
    "plt.show()\n",
    "\n",
    "submition_filename = \"{}-retrain_feature_test.csv\".format(model_save_name)\n",
    "test_df.to_csv(submition_filename,index=False)\n",
    "print(submition_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-fold avg feature test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T17:06:41.547583Z",
     "start_time": "2019-08-24T17:06:41.135277Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr-0824_17-01-06-5-fold_avg_logits_test.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "b3_test_avg_feats = np.average(b3_test_feats_list, axis=0)\n",
    "b4_test_avg_feats = np.average(b4_test_feats_list, axis=0)\n",
    "b5_test_avg_feats = np.average(b5_test_feats_list, axis=0)\n",
    "\n",
    "\n",
    "X_test = np.concatenate([b3_test_avg_feats, b4_test_avg_feats, b5_test_avg_feats], axis=1)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "test_df.diagnosis = y_pred.astype(int)\n",
    "\n",
    "test_df.hist()\n",
    "plt.show()\n",
    "\n",
    "submition_filename = \"{}-5-fold_avg_logits_test.csv\".format(model_save_name)\n",
    "test_df.to_csv(submition_filename, index=False)\n",
    "print(submition_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-fold avg logits test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T17:03:42.516406Z",
     "start_time": "2019-08-24T17:03:41.896426Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr-0824_17-01-06-5-fold_avg_logits_test.csv\n"
     ]
    }
   ],
   "source": [
    "# 5 test feature then avg\n",
    "results = []\n",
    "for b3, b4, b5 in zip(b3_test_feats_list, b4_test_feats_list, b5_test_feats_list):\n",
    "    X_test = np.concatenate([b3, b4, b5], axis=1)\n",
    "    res = lr.predict_proba(X_test)\n",
    "    results.append(res)\n",
    "\n",
    "avg_res = np.average(results, axis=0)\n",
    "y_pred = np.argmax(avg_res, axis=1)\n",
    "\n",
    "test_df.diagnosis = y_pred.astype(int)\n",
    "\n",
    "test_df.hist()\n",
    "plt.show()\n",
    "\n",
    "submition_filename = \"{}-5-fold_avg_logits_test.csv\".format(model_save_name)\n",
    "test_df.to_csv(submition_filename, index=False)\n",
    "print(submition_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-test]",
   "language": "python",
   "name": "conda-env-.conda-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "240.656px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
